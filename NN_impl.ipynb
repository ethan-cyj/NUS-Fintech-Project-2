{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\").dropna()\n",
    "test = pd.read_csv(\"test.csv\").dropna()\n",
    "y_train = np.array(train['Sentiment'])\n",
    "y_test = np.array(test['Sentiment'])\n",
    "X_train = train.drop(['Sentiment'], axis=1)\n",
    "X_train = X_train.values\n",
    "X_test = test.drop(['Sentiment'], axis=1).values\n",
    "gen_features = ['word_count', 'unigram_count', 'unique_word_count', 'unique_unigram_count', 'stopword_count', 'mean_word_length', 'mean_unigram_length', 'char_count', 'punctuation_count', 'number_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 1s 2ms/step - loss: 3.3118 - accuracy: 0.0758 - val_loss: 0.6839 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.6824 - accuracy: 0.2368 - val_loss: 4.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.4513 - accuracy: 0.3567 - val_loss: 4.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.4159 - accuracy: 0.4819 - val_loss: 4.5713 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.4445 - accuracy: 0.4197 - val_loss: 4.5523 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.4920 - accuracy: 0.3413 - val_loss: 4.5356 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.3408 - accuracy: 0.4606 - val_loss: 4.5227 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.3374 - accuracy: 0.4985 - val_loss: 4.5084 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2754 - accuracy: 0.5287 - val_loss: 4.4904 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2798 - accuracy: 0.5149 - val_loss: 4.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2853 - accuracy: 0.5217 - val_loss: 4.4630 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2324 - accuracy: 0.5449 - val_loss: 4.4492 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2257 - accuracy: 0.5377 - val_loss: 4.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.2168 - accuracy: 0.5373 - val_loss: 4.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 2.1972 - accuracy: 0.5473 - val_loss: 4.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1859 - accuracy: 0.5507 - val_loss: 4.3960 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1706 - accuracy: 0.5517 - val_loss: 4.3808 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1522 - accuracy: 0.5518 - val_loss: 4.3673 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1503 - accuracy: 0.5466 - val_loss: 4.3527 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1231 - accuracy: 0.5530 - val_loss: 4.3417 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.1127 - accuracy: 0.5517 - val_loss: 4.3289 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0971 - accuracy: 0.5509 - val_loss: 4.3156 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0888 - accuracy: 0.5520 - val_loss: 4.3030 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0660 - accuracy: 0.5541 - val_loss: 4.2906 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0648 - accuracy: 0.5534 - val_loss: 4.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0545 - accuracy: 0.5537 - val_loss: 4.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0347 - accuracy: 0.5534 - val_loss: 4.2543 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0399 - accuracy: 0.5419 - val_loss: 4.2481 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0207 - accuracy: 0.5526 - val_loss: 4.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 2.0155 - accuracy: 0.5535 - val_loss: 4.2264 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9989 - accuracy: 0.5541 - val_loss: 4.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9878 - accuracy: 0.5539 - val_loss: 4.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9755 - accuracy: 0.5539 - val_loss: 4.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9737 - accuracy: 0.5515 - val_loss: 4.1834 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9610 - accuracy: 0.5469 - val_loss: 4.1764 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9482 - accuracy: 0.5507 - val_loss: 4.1706 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9438 - accuracy: 0.5494 - val_loss: 4.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9351 - accuracy: 0.5485 - val_loss: 4.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9237 - accuracy: 0.5496 - val_loss: 4.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9177 - accuracy: 0.5462 - val_loss: 4.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.9011 - accuracy: 0.5437 - val_loss: 4.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8895 - accuracy: 0.5417 - val_loss: 4.1248 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 1.8825 - accuracy: 0.5371 - val_loss: 4.1177 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8697 - accuracy: 0.5313 - val_loss: 4.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8543 - accuracy: 0.5283 - val_loss: 4.1037 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8801 - accuracy: 0.4951 - val_loss: 4.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8858 - accuracy: 0.5034 - val_loss: 4.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8685 - accuracy: 0.5275 - val_loss: 4.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8622 - accuracy: 0.5368 - val_loss: 4.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 1.8507 - accuracy: 0.5241 - val_loss: 4.1002 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f64ad650>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, activation='tanh'))  # Output layer\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "# Fit the model - assuming your data is ready and appropriately preprocessed\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 923us/step\n",
      "AUC: 0.5063968870092501\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "print(f'AUC: {roc_auc_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
